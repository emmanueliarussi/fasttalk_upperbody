{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3b502c",
   "metadata": {},
   "source": [
    "# SMPL-X + FLAME (Fused) Sequence Preview\n",
    "This notebook loads tracking PKLs, builds the fused SMPL-X model (with FLAME head merging built-in), renders a quick shaded preview, and writes H.264 MP4 output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf14c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports + environment setup (headless-friendly)\n",
    "import os\n",
    "# Work from repo root to keep relative imports consistent\n",
    "os.chdir('../')\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "# Project rendering utils\n",
    "from renderer.util import batch_orth_proj, vertex_normals, face_vertices\n",
    "from renderer.renderer import Renderer\n",
    "\n",
    "# Make local fused SMPL-X wrapper importable (uses smplx/SMPLX.py)\n",
    "sys.path.append('/mnt/fasttalk_upperbody/smplx')\n",
    "from SMPLX import SMPLX as SMPLX_Fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34bc04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/mnt/GUAVA/assets/example/tracked_video/6gvP8f5WQyo__056/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf696c",
   "metadata": {},
   "source": [
    "## Select Input Sequence\n",
    "Set `base_path` to the directory containing the tracking PKLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f3c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['frame_000000', 'frame_000001', 'frame_000002', 'frame_000003', 'frame_000004', 'frame_000005', 'frame_000006', 'frame_000007', 'frame_000008', 'frame_000009', 'frame_000010', 'frame_000011', 'frame_000012', 'frame_000013', 'frame_000014', 'frame_000015', 'frame_000016', 'frame_000017', 'frame_000018', 'frame_000019', 'frame_000020', 'frame_000021', 'frame_000022', 'frame_000023', 'frame_000024', 'frame_000025', 'frame_000026', 'frame_000027', 'frame_000028', 'frame_000029', 'frame_000030', 'frame_000031', 'frame_000032', 'frame_000033', 'frame_000034', 'frame_000035', 'frame_000036', 'frame_000037', 'frame_000038', 'frame_000039', 'frame_000040', 'frame_000041', 'frame_000042', 'frame_000043', 'frame_000044', 'frame_000045', 'frame_000046', 'frame_000047', 'frame_000048', 'frame_000049', 'frame_000050', 'frame_000051', 'frame_000052', 'frame_000053', 'frame_000054', 'frame_000055', 'frame_000056', 'frame_000057', 'frame_000058', 'frame_000059', 'frame_000060', 'frame_000061', 'frame_000062', 'frame_000063', 'frame_000064', 'frame_000065', 'frame_000066', 'frame_000067', 'frame_000068', 'frame_000069', 'frame_000070', 'frame_000071', 'frame_000072', 'frame_000073', 'frame_000074', 'frame_000075', 'frame_000076', 'frame_000077', 'frame_000078', 'frame_000079', 'frame_000080', 'frame_000081', 'frame_000082', 'frame_000083', 'frame_000084', 'frame_000085', 'frame_000086', 'frame_000087', 'frame_000088', 'frame_000089', 'frame_000090', 'frame_000091', 'frame_000092', 'frame_000093', 'frame_000094', 'frame_000095', 'frame_000096', 'frame_000097', 'frame_000098', 'frame_000099', 'frame_000100', 'frame_000101', 'frame_000102', 'frame_000103', 'frame_000104', 'frame_000105', 'frame_000106', 'frame_000107', 'frame_000108', 'frame_000109', 'frame_000110', 'frame_000111', 'frame_000112', 'frame_000113', 'frame_000114', 'frame_000115', 'frame_000116', 'frame_000117', 'frame_000118', 'frame_000119', 'frame_000120', 'frame_000121', 'frame_000122', 'frame_000123', 'frame_000124', 'frame_000125', 'frame_000126', 'frame_000127', 'frame_000128', 'frame_000129', 'frame_000130', 'frame_000131', 'frame_000132', 'frame_000133', 'frame_000134', 'frame_000135', 'frame_000136', 'frame_000137', 'frame_000138', 'frame_000139', 'frame_000140', 'frame_000141', 'frame_000142', 'frame_000143', 'frame_000144', 'frame_000145', 'frame_000146', 'frame_000147', 'frame_000148', 'frame_000149', 'frame_000150', 'frame_000151', 'frame_000152', 'frame_000153', 'frame_000154', 'frame_000155', 'frame_000156', 'frame_000157', 'frame_000158', 'frame_000159', 'frame_000160', 'frame_000161', 'frame_000162', 'frame_000163', 'frame_000164', 'frame_000165', 'frame_000166', 'frame_000167', 'frame_000168', 'frame_000169', 'frame_000170', 'frame_000171', 'frame_000172', 'frame_000173', 'frame_000174', 'frame_000175', 'frame_000176', 'frame_000177', 'frame_000178', 'frame_000179', 'frame_000180', 'frame_000181', 'frame_000182', 'frame_000183', 'frame_000184', 'frame_000185', 'frame_000186', 'frame_000187', 'frame_000188', 'frame_000189', 'frame_000190', 'frame_000191', 'frame_000192', 'frame_000193', 'frame_000194', 'frame_000195', 'frame_000196', 'frame_000197', 'frame_000198', 'frame_000199', 'frame_000200', 'frame_000201', 'frame_000202', 'frame_000203', 'frame_000204', 'frame_000205', 'frame_000206', 'frame_000207', 'frame_000208', 'frame_000209', 'frame_000210', 'frame_000211', 'frame_000212', 'frame_000213', 'frame_000214', 'frame_000215', 'frame_000216', 'frame_000217', 'frame_000218', 'frame_000219', 'frame_000220', 'frame_000221', 'frame_000222', 'frame_000223', 'frame_000224', 'frame_000225', 'frame_000226', 'frame_000227', 'frame_000228', 'frame_000229', 'frame_000230', 'frame_000231', 'frame_000232', 'frame_000233', 'frame_000234', 'frame_000235', 'frame_000236', 'frame_000237', 'frame_000238', 'frame_000239', 'frame_000240', 'frame_000241', 'frame_000242', 'frame_000243', 'frame_000244', 'frame_000245', 'frame_000246', 'frame_000247', 'frame_000248', 'frame_000249', 'frame_000250', 'frame_000251', 'frame_000252', 'frame_000253', 'frame_000254', 'frame_000255', 'frame_000256', 'frame_000257', 'frame_000258', 'frame_000259', 'frame_000260', 'frame_000261', 'frame_000262', 'frame_000263', 'frame_000264', 'frame_000265', 'frame_000266', 'frame_000267', 'frame_000268', 'frame_000269', 'frame_000270', 'frame_000271', 'frame_000272', 'frame_000273', 'frame_000274', 'frame_000275', 'frame_000276', 'frame_000277', 'frame_000278', 'frame_000279', 'frame_000280', 'frame_000281', 'frame_000282', 'frame_000283', 'frame_000284', 'frame_000285', 'frame_000286', 'frame_000287', 'frame_000288', 'frame_000289', 'frame_000290', 'frame_000291', 'frame_000292', 'frame_000293', 'frame_000294', 'frame_000295', 'frame_000296', 'frame_000297', 'frame_000298', 'frame_000299', 'frame_000300', 'frame_000301', 'frame_000302', 'frame_000303', 'frame_000304', 'frame_000305', 'frame_000306', 'frame_000307', 'frame_000308', 'frame_000309', 'frame_000310', 'frame_000311', 'frame_000312', 'frame_000313', 'frame_000314', 'frame_000315', 'frame_000316', 'frame_000317', 'frame_000318', 'frame_000319', 'frame_000320', 'frame_000321', 'frame_000322', 'frame_000323', 'frame_000324', 'frame_000325', 'frame_000326', 'frame_000327', 'frame_000328', 'frame_000329', 'frame_000330', 'frame_000331', 'frame_000332', 'frame_000333', 'frame_000334', 'frame_000335', 'frame_000336', 'frame_000337', 'frame_000338', 'frame_000339', 'frame_000340', 'frame_000341', 'frame_000342', 'frame_000343', 'frame_000344', 'frame_000345', 'frame_000346', 'frame_000347', 'frame_000348', 'frame_000349', 'frame_000350', 'frame_000351', 'frame_000352', 'frame_000353', 'frame_000354', 'frame_000355', 'frame_000356', 'frame_000357', 'frame_000358', 'frame_000359', 'frame_000360', 'frame_000361', 'frame_000362', 'frame_000363', 'frame_000364', 'frame_000365', 'frame_000366', 'frame_000367', 'frame_000368', 'frame_000369', 'frame_000370', 'frame_000371', 'frame_000372', 'frame_000373', 'frame_000374', 'frame_000375', 'frame_000376', 'frame_000377', 'frame_000378', 'frame_000379', 'frame_000380', 'frame_000381', 'frame_000382', 'frame_000383', 'frame_000384', 'frame_000385', 'frame_000386', 'frame_000387', 'frame_000388', 'frame_000389', 'frame_000390', 'frame_000391', 'frame_000392', 'frame_000393', 'frame_000394', 'frame_000395', 'frame_000396', 'frame_000397', 'frame_000398', 'frame_000399', 'frame_000400', 'frame_000401', 'frame_000402', 'frame_000403', 'frame_000404', 'frame_000405', 'frame_000406', 'frame_000407', 'frame_000408', 'frame_000409', 'frame_000410', 'frame_000411', 'frame_000412', 'frame_000413', 'frame_000414', 'frame_000415', 'frame_000416', 'frame_000417', 'frame_000418', 'frame_000419', 'frame_000420', 'frame_000421', 'frame_000422', 'frame_000423', 'frame_000424'])\n",
      "dict_keys(['body_crop', 'dwpose_raw', 'dwpose_rlt', 'smplx_coeffs', 'head_crop', 'head_lmk_203', 'head_lmk_70', 'head_lmk_mp', 'flame_coeffs', 'left_mano_coeffs', 'left_hand_crop', 'right_mano_coeffs', 'right_hand_crop'])\n"
     ]
    }
   ],
   "source": [
    "tracking_path = base_path + \"optim_tracking_ehm.pkl\"\n",
    "\n",
    "with open(tracking_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Print the keys of the dictionary to see what it contains\n",
    "print(data.keys())\n",
    "print(data['frame_000000'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49785b15",
   "metadata": {},
   "source": [
    "## Inspect Tracking PKL\n",
    "Quickly peek at the top-level keys and the first frameâ€™s fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a53ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in frame: dict_keys(['body_crop', 'dwpose_raw', 'dwpose_rlt', 'smplx_coeffs', 'head_crop', 'head_lmk_203', 'head_lmk_70', 'head_lmk_mp', 'flame_coeffs', 'left_mano_coeffs', 'left_hand_crop', 'right_mano_coeffs', 'right_hand_crop'])\n",
      "\n",
      "Keys in smplx_coeffs: dict_keys(['exp', 'global_pose', 'body_pose', 'body_cam', 'camera_RT_params', 'left_hand_pose', 'right_hand_pose'])\n",
      "\n",
      "=== Detailed structure of smplx_coeffs ===\n",
      "exp: shape=(50,), dtype=float32, first few values: [1.2100561  0.5304717  0.11870743 0.19686127 0.08652326]\n",
      "global_pose: shape=(3,), dtype=float32, first few values: [ 2.9868624   0.06696548 -0.25063005]\n",
      "body_pose: shape=(21, 3), dtype=float32, first few values: [-0.05537486  0.08022741  0.00862682 -0.0110795  -0.00271257]\n",
      "body_cam: shape=(3,), dtype=float32, first few values: [1.9841318  0.05343538 0.83356845]\n",
      "camera_RT_params: shape=(3, 4), dtype=float32, first few values: [-0.9999938  -0.00333516  0.00106661 -0.04895249  0.00326747]\n",
      "left_hand_pose: shape=(15, 3), dtype=float32, first few values: [-0.08508328  0.12008699 -1.3282686   0.20950751 -0.20685533]\n",
      "right_hand_pose: shape=(15, 3), dtype=float32, first few values: [ 0.00409186 -0.321227    0.8929021   0.41290188  0.21008031]\n"
     ]
    }
   ],
   "source": [
    "# Check what's actually in the nested structure\n",
    "sample_frame = data['frame_000000']\n",
    "print(\"Keys in frame:\", sample_frame.keys())\n",
    "print(\"\\nKeys in smplx_coeffs:\", sample_frame['smplx_coeffs'].keys())\n",
    "print(\"\\n=== Detailed structure of smplx_coeffs ===\")\n",
    "for key, value in sample_frame['smplx_coeffs'].items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"{key}: shape={value.shape}, dtype={value.dtype}, first few values: {value.flatten()[:5]}\")\n",
    "    else:\n",
    "        print(f\"{key}: type={type(value)} -> {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19edacec",
   "metadata": {},
   "source": [
    "## Inspect `smplx_coeffs` Structure\n",
    "Print shapes and a few values to confirm expected dimensions and ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e2ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape file not found, using default neutral betas\n",
      "Betas provided: 10\n",
      "Frames: 425\n",
      "Found dims -> expr:50 body:63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/fasttalk/lib/python3.11/site-packages/pytorch3d/ops/laplacian_matrices.py:51: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:654.)\n",
      "  A = torch.sparse.FloatTensor(idx, ones, (V, V))\n"
     ]
    }
   ],
   "source": [
    "# Build fused SMPL-X model, parse coeffs, and prep camera/render context (no PCA hands, keep 45D)\n",
    "from pathlib import Path\n",
    "\n",
    "# Files\n",
    "shape_path = base_path + 'id_share_params.pkl'\n",
    "tracking_path = base_path + 'optim_tracking_ehm.pkl'\n",
    "\n",
    "# Load shape data if available, otherwise use defaults\n",
    "if Path(shape_path).exists():\n",
    "    with open(shape_path, 'rb') as f:\n",
    "        shape_data = pickle.load(f)\n",
    "    betas_np = np.asarray(shape_data.get('smplx_shape'))  # often (1, 200)\n",
    "    betas_np = betas_np.reshape(1, -1) if betas_np.ndim == 1 else betas_np\n",
    "    print('Loaded betas from file')\n",
    "else:\n",
    "    # Use default neutral shape (zeros)\n",
    "    betas_np = np.zeros((1, 10), dtype=np.float32)\n",
    "    print('Shape file not found, using default neutral betas')\n",
    "\n",
    "betas_full = torch.from_numpy(betas_np).float()\n",
    "print('Betas provided:', betas_full.shape[1])\n",
    "\n",
    "# Load tracking data\n",
    "with open(tracking_path, 'rb') as f:\n",
    "    tracking = pickle.load(f)\n",
    "\n",
    "frame_keys = sorted([k for k in tracking.keys() if k.startswith('frame_')])\n",
    "assert len(frame_keys) > 0, 'No frames found in tracking PKL'\n",
    "print('Frames:', len(frame_keys))\n",
    "\n",
    "# Inspect first frame to determine expression dim\n",
    "def get_inner_coeffs(fd):\n",
    "    return fd['smplx_coeffs'] if isinstance(fd, dict) and 'smplx_coeffs' in fd else fd\n",
    "\n",
    "sample = get_inner_coeffs(tracking[frame_keys[0]])\n",
    "\n",
    "def get_len(d, keys, default=None):\n",
    "    for k in keys:\n",
    "        if k in d and d[k] is not None:\n",
    "            v = np.asarray(d[k]).reshape(-1)\n",
    "            return v.shape[0]\n",
    "    return default\n",
    "\n",
    "expr_dim_in = get_len(sample, ['expression','expr'], 50)\n",
    "body_dim_in = get_len(sample, ['body_pose','body','pose_body'], 63)\n",
    "print(f'Found dims -> expr:{expr_dim_in} body:{body_dim_in}')\n",
    "\n",
    "# Use the provided fused SMPLX wrapper that handles head/hand regions internally\n",
    "from SMPLX import SMPLX as SMPLX_Fused\n",
    "smplx_model_dir = '/mnt/fasttalk_upperbody/smplx'  # assets dir with SMPLX npz and aux files\n",
    "assert Path(smplx_model_dir).exists(), f'Missing SMPLX assets at {smplx_model_dir}'\n",
    "smplx_fused = SMPLX_Fused(smplx_model_dir, n_shape=200, n_exp=50).to('cuda' if torch.cuda.is_available() else 'cpu').eval()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Expected dims for parsing (match fused model)\n",
    "n_exp_model = 50\n",
    "\n",
    "# Faces (triangles) for rendering: use fused model's faces directly\n",
    "faces_t = smplx_fused.faces_tensor[None, ...].to(device)\n",
    "\n",
    "def to_row_tensor(arr):\n",
    "    if arr is None:\n",
    "        return None\n",
    "    t = torch.from_numpy(np.asarray(arr).reshape(-1)).float()\n",
    "    return t[None, :]\n",
    "\n",
    "def fit_dim_row(t, target):\n",
    "    if t is None:\n",
    "        return torch.zeros(1, target).float()\n",
    "    if t.shape[1] > target:\n",
    "        return t[:, :target]\n",
    "    if t.shape[1] < target:\n",
    "        return torch.cat([t, torch.zeros(1, target - t.shape[1], dtype=t.dtype)], dim=1)\n",
    "    return t\n",
    "\n",
    "def first_val(d, keys):\n",
    "    for k in keys:\n",
    "        if k in d and d[k] is not None:\n",
    "            return d[k]\n",
    "    return None\n",
    "\n",
    "def parse_frame(fd):\n",
    "    # Align with project data_loader: use only smplx_coeffs entries, no MANO fallbacks\n",
    "    d = get_inner_coeffs(fd)\n",
    "\n",
    "    # Global/body/face\n",
    "    go  = to_row_tensor(first_val(d, ['global_pose','global_orient','root_orient','orient']))\n",
    "    bp  = to_row_tensor(first_val(d, ['body_pose','body','pose_body']))\n",
    "    jp  = to_row_tensor(first_val(d, ['jaw_pose','jaw']))\n",
    "    lep = to_row_tensor(first_val(d, ['leye_pose','left_eye_pose']))\n",
    "    rep = to_row_tensor(first_val(d, ['reye_pose','right_eye_pose']))\n",
    "\n",
    "    # Hands: strictly use SMPL-X hand pose from smplx_coeffs (axis-angle, 45D)\n",
    "    lhp = to_row_tensor(d.get('left_hand_pose'))\n",
    "    rhp = to_row_tensor(d.get('right_hand_pose'))\n",
    "\n",
    "    exp = to_row_tensor(first_val(d, ['exp','expression','expr']))\n",
    "    trn = to_row_tensor(first_val(d, ['transl','translation','trans']))\n",
    "\n",
    "    # Fit dims (keep as flat row tensors, SMPL-X expects this)\n",
    "    go  = fit_dim_row(go, 3)                         # (1,3)\n",
    "    bp  = fit_dim_row(bp, 63)                        # (1,63)\n",
    "    jp  = fit_dim_row(jp, 3)                         # (1,3)\n",
    "    lep = fit_dim_row(lep, 3)                        # (1,3)\n",
    "    rep = fit_dim_row(rep, 3)                        # (1,3)\n",
    "    lhp = fit_dim_row(lhp, 45)                       # (1,45)\n",
    "    rhp = fit_dim_row(rhp, 45)                       # (1,45)\n",
    "    exp = fit_dim_row(exp, n_exp_model)              # (1,n_exp)\n",
    "    trn = fit_dim_row(trn, 3)                        # (1,3)\n",
    "    return {\n",
    "        'global_orient': go,\n",
    "        'body_pose': bp,\n",
    "        'jaw_pose': jp,\n",
    "        'leye_pose': lep,\n",
    "        'reye_pose': rep,\n",
    "        'left_hand_pose': lhp,\n",
    "        'right_hand_pose': rhp,\n",
    "        'expression': exp,\n",
    "        'transl': trn,\n",
    "    }\n",
    "\n",
    "# Helper: build param_dict for SMPLX_Fused (axis-angle grouped per joint)\n",
    "def build_param_dict(coeffs, prefer_flame=True, fd=None):\n",
    "    # choose expression/eyes from flame if available\n",
    "    exp = None\n",
    "    eye_l = coeffs['leye_pose']\n",
    "    eye_r = coeffs['reye_pose']\n",
    "    if prefer_flame and isinstance(fd, dict) and 'flame_coeffs' in fd:\n",
    "        f = fd['flame_coeffs']\n",
    "        if 'expression' in f or 'exp' in f or 'expression_params' in f:\n",
    "            v = first_val(f, ['expression','exp','expression_params'])\n",
    "            if v is not None:\n",
    "                exp = torch.from_numpy(np.asarray(v).reshape(1, -1)).float()\n",
    "        le = first_val(f, ['leye_pose','left_eye_pose'])\n",
    "        re = first_val(f, ['reye_pose','right_eye_pose'])\n",
    "        if le is not None:\n",
    "            eye_l = torch.from_numpy(np.asarray(le).reshape(1, -1)).float()\n",
    "        if re is not None:\n",
    "            eye_r = torch.from_numpy(np.asarray(re).reshape(1, -1)).float()\n",
    "    if exp is None:\n",
    "        exp = coeffs['expression']\n",
    "    # reshape to [B,*,3]\n",
    "    B = 1\n",
    "    param = {\n",
    "        'shape': betas_full[:, :200].to(device),\n",
    "        'exp': torch.cat([exp, torch.zeros(B, max(0, 50-exp.shape[1]))], dim=1)[:, :50].to(device),\n",
    "        'global_pose': coeffs['global_orient'].reshape(B, 1, 3).to(device),\n",
    "        'body_pose': coeffs['body_pose'].reshape(B, 21, 3).to(device),\n",
    "        'jaw_pose': coeffs['jaw_pose'].reshape(B, 1, 3).to(device),\n",
    "        'left_hand_pose': coeffs['left_hand_pose'].reshape(B, 15, 3).to(device),\n",
    "        'right_hand_pose': coeffs['right_hand_pose'].reshape(B, 15, 3).to(device),\n",
    "        'eye_pose': torch.cat([eye_l.reshape(B,1,3), eye_r.reshape(B,1,3)], dim=1).to(device),\n",
    "        # translate whole body by transl via joints_offset\n",
    "        'joints_offset': coeffs['transl'].reshape(B,1,3).expand(B, smplx_fused.J_regressor.shape[0], 3).to(device),\n",
    "    }\n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451bba6",
   "metadata": {},
   "source": [
    "## Fused SMPL-X Setup + Parsers\n",
    "Build the fused model (which already merges the FLAME head), define simple helpers to parse and pad inputs, and create a param builder that prefers FLAME expression/eyes when present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc6c868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fused SMPL-X model info ===\n",
      "shapedirs: (10475, 3, 250)\n",
      "J_regressor: (55, 10475)\n",
      "faces: 20908 tris\n",
      "n_shape: 200  n_exp: 50\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Debug: print fused model internal dimensions (no vanilla smplx)\n",
    "print('=== Fused SMPL-X model info ===')\n",
    "print(f'shapedirs: {tuple(smplx_fused.shapedirs.shape)}')\n",
    "print(f'J_regressor: {tuple(smplx_fused.J_regressor.shape)}')\n",
    "print(f'faces: {int(smplx_fused.faces_tensor.shape[0])} tris')\n",
    "print(f'n_shape: {smplx_fused.n_shape}  n_exp: {smplx_fused.n_exp}')\n",
    "print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00720370",
   "metadata": {},
   "source": [
    "## Model Internals\n",
    "Confirm model buffers and dimensions to help spot mismatches early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c95212ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices shape: (1, 10475, 3) min/max: -1.111258625984192 0.5983074903488159\n"
     ]
    }
   ],
   "source": [
    "# Quick shape sanity check using fused forward on first frame\n",
    "with torch.no_grad():\n",
    "    coeffs0 = parse_frame(tracking[frame_keys[0]])\n",
    "    param0 = build_param_dict(coeffs0, prefer_flame=True, fd=tracking[frame_keys[0]])\n",
    "    out0 = smplx_fused(param0)\n",
    "    v0 = out0['vertices']\n",
    "    print('vertices shape:', tuple(v0.shape), 'min/max:', float(v0.min()), float(v0.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3506ede1",
   "metadata": {},
   "source": [
    "## Sanity Check Vertices\n",
    "Run one fused forward pass on the first frame to confirm shapes and reasonable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f229a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left hand pose (len): 45 first 6: tensor([-0.0851,  0.1201, -1.3283,  0.2095, -0.2069, -0.6650])\n",
      "Right hand pose (len): 45 first 6: tensor([ 0.0041, -0.3212,  0.8929,  0.4129,  0.2101,  1.1837])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check hands after parser simplification\n",
    "fp = parse_frame(tracking[frame_keys[0]])\n",
    "print('Left hand pose (len):', fp['left_hand_pose'].shape[1], 'first 6:', fp['left_hand_pose'][0, :6])\n",
    "print('Right hand pose (len):', fp['right_hand_pose'].shape[1], 'first 6:', fp['right_hand_pose'][0, :6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89888cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ffmpeg (libx264) for H.264 encoding\n",
      "Rendering 425 frames using SMPLX.py fusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 9c33b2f Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/fasttalk --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/pkg-config\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "/mnt/fasttalk_upperbody/renderer/util.py:53: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at /pytorch/aten/src/ATen/native/Cross.cpp:62.)\n",
      "  torch.cross(vertices_faces[:, 2] - vertices_faces[:, 1], vertices_faces[:, 0] - vertices_faces[:, 1]))\n",
      "Input #0, rawvideo, from 'pipe:':\n",
      "  Duration: N/A, start: 0.000000, bitrate: 384000 kb/s\n",
      "    Stream #0:0: Video: rawvideo (RGB[24] / 0x18424752), rgb24, 800x800, 384000 kb/s, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (rawvideo (native) -> h264 (libx264))\n",
      "[libx264 @ 0x55ba8b0ff1c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "[libx264 @ 0x55ba8b0ff1c0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55ba8b0ff1c0] 264 - core 161 r3030M 8bd6d28 - H.264/MPEG-4 AVC codec - Copyleft 2003-2020 - http://www.videolan.org/x264.html - options: cabac=1 ref=1 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=2 psy=1 psy_rd=1.00:0.00 mixed_ref=0 me_range=16 chroma_me=1 trellis=0 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=0 threads=25 lookahead_threads=6 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=1 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=10 rc=crf mbtree=1 crf=18.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/mnt/fasttalk_upperbody/demo/smplx_flame_fused.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 800x800, q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.91.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 5/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=    7 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 10/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   12 fps= 11 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 15/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   18 fps= 11 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 20/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   24 fps= 11 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 25/425 frames\n",
      "  Rendered 30/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   30 fps= 11 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 35/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   36 fps= 11 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 40/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   42 fps= 11 q=23.0 size=       0kB time=00:00:00.00 bitrate=4923.1kbits/s speed=2.03e-05x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 45/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   47 fps= 11 q=23.0 size=       0kB time=00:00:00.20 bitrate=   1.9kbits/s speed=0.0457x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 50/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   52 fps= 11 q=23.0 size=       0kB time=00:00:00.40 bitrate=   1.0kbits/s speed=0.0819x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 55/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   57 fps= 10 q=23.0 size=       0kB time=00:00:00.60 bitrate=   0.6kbits/s speed=0.11x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 60/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   63 fps= 10 q=23.0 size=       0kB time=00:00:00.84 bitrate=   0.5kbits/s speed=0.139x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 65/425 frames\n",
      "  Rendered 70/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   70 fps= 11 q=23.0 size=       0kB time=00:00:01.12 bitrate=   0.3kbits/s speed=0.169x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 75/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   76 fps= 11 q=23.0 size=       0kB time=00:00:01.36 bitrate=   0.3kbits/s speed=0.188x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 80/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   82 fps= 11 q=23.0 size=       0kB time=00:00:01.60 bitrate=   0.2kbits/s speed=0.207x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 85/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   86 fps= 10 q=23.0 size=       0kB time=00:00:01.76 bitrate=   0.2kbits/s speed=0.213x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 90/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   92 fps= 10 q=23.0 size=       0kB time=00:00:02.00 bitrate=   0.2kbits/s speed=0.226x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 95/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   98 fps= 10 q=23.0 size=       0kB time=00:00:02.24 bitrate=   0.2kbits/s speed=0.237x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 100/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  104 fps= 10 q=23.0 size=       0kB time=00:00:02.48 bitrate=   0.2kbits/s speed=0.249x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 105/425 frames\n",
      "  Rendered 110/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  110 fps= 10 q=23.0 size=       0kB time=00:00:02.72 bitrate=   0.1kbits/s speed=0.258x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 115/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  117 fps= 10 q=23.0 size=     256kB time=00:00:03.00 bitrate= 699.2kbits/s speed=0.269x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 120/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  123 fps= 11 q=23.0 size=     256kB time=00:00:03.24 bitrate= 647.4kbits/s speed=0.277x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 125/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  129 fps= 11 q=23.0 size=     256kB time=00:00:03.48 bitrate= 602.7kbits/s speed=0.284x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 130/425 frames\n",
      "  Rendered 135/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  135 fps= 11 q=23.0 size=     256kB time=00:00:03.72 bitrate= 563.8kbits/s speed=0.289x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 140/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  142 fps= 11 q=23.0 size=     256kB time=00:00:04.00 bitrate= 524.4kbits/s speed=0.298x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 145/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  148 fps= 11 q=23.0 size=     256kB time=00:00:04.24 bitrate= 494.7kbits/s speed=0.302x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 150/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  154 fps= 11 q=23.0 size=     256kB time=00:00:04.48 bitrate= 468.2kbits/s speed=0.308x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 155/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  159 fps= 11 q=23.0 size=     256kB time=00:00:04.68 bitrate= 448.2kbits/s speed=0.311x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 160/425 frames\n",
      "  Rendered 165/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  165 fps= 11 q=23.0 size=     256kB time=00:00:04.92 bitrate= 426.3kbits/s speed=0.316x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 170/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  171 fps= 11 q=23.0 size=     256kB time=00:00:05.16 bitrate= 406.5kbits/s speed=0.32x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 175/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  177 fps= 11 q=23.0 size=     256kB time=00:00:05.40 bitrate= 388.4kbits/s speed=0.323x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 180/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  183 fps= 11 q=23.0 size=     256kB time=00:00:05.64 bitrate= 371.9kbits/s speed=0.326x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 185/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  189 fps= 11 q=23.0 size=     256kB time=00:00:05.88 bitrate= 356.7kbits/s speed=0.331x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 190/425 frames\n",
      "  Rendered 195/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  195 fps= 11 q=23.0 size=     512kB time=00:00:06.12 bitrate= 685.4kbits/s speed=0.333x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 200/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  202 fps= 11 q=23.0 size=     512kB time=00:00:06.40 bitrate= 655.4kbits/s speed=0.335x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 205/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  209 fps= 11 q=23.0 size=     512kB time=00:00:06.68 bitrate= 627.9kbits/s speed=0.339x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 210/425 frames\n",
      "  Rendered 215/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  215 fps= 11 q=23.0 size=     512kB time=00:00:06.92 bitrate= 606.2kbits/s speed=0.341x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 220/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  221 fps= 11 q=23.0 size=     512kB time=00:00:07.16 bitrate= 585.8kbits/s speed=0.342x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 225/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  227 fps= 11 q=23.0 size=     512kB time=00:00:07.40 bitrate= 566.8kbits/s speed=0.346x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 230/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  233 fps= 11 q=23.0 size=     512kB time=00:00:07.64 bitrate= 549.0kbits/s speed=0.348x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 235/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  238 fps= 11 q=23.0 size=     512kB time=00:00:07.84 bitrate= 535.0kbits/s speed=0.349x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 240/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  243 fps= 11 q=23.0 size=     512kB time=00:00:08.04 bitrate= 521.7kbits/s speed=0.349x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 245/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  248 fps= 11 q=23.0 size=     512kB time=00:00:08.24 bitrate= 509.1kbits/s speed=0.349x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 250/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  254 fps= 10 q=23.0 size=     512kB time=00:00:08.48 bitrate= 494.7kbits/s speed=0.35x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 255/425 frames\n",
      "  Rendered 260/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  260 fps= 11 q=23.0 size=     512kB time=00:00:08.72 bitrate= 481.0kbits/s speed=0.353x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 265/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  266 fps= 10 q=20.0 size=     512kB time=00:00:08.96 bitrate= 468.2kbits/s speed=0.353x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 270/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  272 fps= 11 q=23.0 size=     768kB time=00:00:09.20 bitrate= 683.9kbits/s speed=0.355x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 275/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  277 fps= 10 q=23.0 size=     768kB time=00:00:09.40 bitrate= 669.3kbits/s speed=0.355x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 280/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  282 fps= 10 q=23.0 size=     768kB time=00:00:09.60 bitrate= 655.4kbits/s speed=0.355x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 285/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  287 fps= 10 q=23.0 size=     768kB time=00:00:09.80 bitrate= 642.0kbits/s speed=0.356x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 290/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  293 fps= 10 q=23.0 size=     768kB time=00:00:10.04 bitrate= 626.7kbits/s speed=0.357x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 295/425 frames\n",
      "  Rendered 300/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  300 fps= 10 q=23.0 size=     768kB time=00:00:10.32 bitrate= 609.7kbits/s speed=0.359x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 305/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  307 fps= 10 q=23.0 size=     768kB time=00:00:10.60 bitrate= 593.6kbits/s speed=0.362x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 310/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  313 fps= 10 q=23.0 size=     768kB time=00:00:10.84 bitrate= 580.4kbits/s speed=0.362x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 315/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  319 fps= 10 q=23.0 size=     768kB time=00:00:11.08 bitrate= 567.9kbits/s speed=0.363x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 320/425 frames\n",
      "  Rendered 325/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  325 fps= 10 q=23.0 size=     768kB time=00:00:11.32 bitrate= 555.8kbits/s speed=0.364x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 330/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  332 fps= 10 q=23.0 size=     768kB time=00:00:11.60 bitrate= 542.4kbits/s speed=0.365x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 335/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  339 fps= 10 q=23.0 size=     768kB time=00:00:11.88 bitrate= 529.6kbits/s speed=0.366x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 340/425 frames\n",
      "  Rendered 345/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  346 fps= 10 q=23.0 size=     768kB time=00:00:12.16 bitrate= 517.4kbits/s speed=0.367x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 350/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  352 fps= 10 q=23.0 size=    1024kB time=00:00:12.40 bitrate= 676.5kbits/s speed=0.368x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 355/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  358 fps= 10 q=23.0 size=    1024kB time=00:00:12.64 bitrate= 663.7kbits/s speed=0.37x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 360/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  364 fps= 10 q=23.0 size=    1024kB time=00:00:12.88 bitrate= 651.3kbits/s speed=0.37x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 365/425 frames\n",
      "  Rendered 370/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  370 fps= 10 q=23.0 size=    1024kB time=00:00:13.12 bitrate= 639.4kbits/s speed=0.371x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 375/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  376 fps= 10 q=23.0 size=    1024kB time=00:00:13.36 bitrate= 627.9kbits/s speed=0.372x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 380/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  382 fps= 10 q=23.0 size=    1024kB time=00:00:13.60 bitrate= 616.8kbits/s speed=0.374x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 385/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  388 fps= 11 q=23.0 size=    1024kB time=00:00:13.84 bitrate= 606.1kbits/s speed=0.375x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 390/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  392 fps= 10 q=23.0 size=    1024kB time=00:00:14.00 bitrate= 599.2kbits/s speed=0.374x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 395/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  398 fps= 10 q=23.0 size=    1024kB time=00:00:14.24 bitrate= 589.1kbits/s speed=0.374x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 400/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  404 fps= 10 q=23.0 size=    1024kB time=00:00:14.48 bitrate= 579.3kbits/s speed=0.375x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 405/425 frames\n",
      "  Rendered 410/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  411 fps= 10 q=23.0 size=    1024kB time=00:00:14.76 bitrate= 568.4kbits/s speed=0.376x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 415/425 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  418 fps= 10 q=23.0 size=    1024kB time=00:00:15.04 bitrate= 557.8kbits/s speed=0.377x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rendered 420/425 frames\n",
      "  Rendered 425/425 frames\n",
      "âœ“ Saved video to /mnt/fasttalk_upperbody/demo/smplx_flame_fused.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  425 fps= 10 q=-1.0 Lsize=    1385kB time=00:00:16.88 bitrate= 672.0kbits/s speed=0.416x    \n",
      "video:1379kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.421376%\n",
      "[libx264 @ 0x55ba8b0ff1c0] frame I:2     Avg QP: 6.37  size: 13507\n",
      "[libx264 @ 0x55ba8b0ff1c0] frame P:107   Avg QP:16.17  size:  6095\n",
      "[libx264 @ 0x55ba8b0ff1c0] frame B:316   Avg QP:19.46  size:  2317\n",
      "[libx264 @ 0x55ba8b0ff1c0] consecutive B-frames:  0.7%  0.5%  0.0% 98.8%\n",
      "[libx264 @ 0x55ba8b0ff1c0] mb I  I16..4: 75.8% 12.1% 12.1%\n",
      "[libx264 @ 0x55ba8b0ff1c0] mb P  I16..4:  3.1%  4.1%  1.9%  P16..4:  6.7%  5.7%  3.1%  0.0%  0.0%    skip:75.4%\n",
      "[libx264 @ 0x55ba8b0ff1c0] mb B  I16..4:  0.5%  0.2%  0.1%  B16..8:  8.1%  4.3%  0.8%  direct: 2.6%  skip:83.3%  L0:46.2% L1:41.9% BI:11.8%\n",
      "[libx264 @ 0x55ba8b0ff1c0] 8x8 transform intra:37.1% inter:7.7%\n",
      "[libx264 @ 0x55ba8b0ff1c0] coded y,uvDC,uvAC intra: 40.0% 60.3% 34.7% inter: 2.3% 4.6% 0.9%\n",
      "[libx264 @ 0x55ba8b0ff1c0] i16 v,h,dc,p: 74%  8%  6% 11%\n",
      "[libx264 @ 0x55ba8b0ff1c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 45% 11%  9%  4%  6%  9%  5%  7%  3%\n",
      "[libx264 @ 0x55ba8b0ff1c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 14% 15%  6% 10%  9%  9%  6%  4%\n",
      "[libx264 @ 0x55ba8b0ff1c0] i8c dc,h,v,p: 39% 11% 37% 13%\n",
      "[libx264 @ 0x55ba8b0ff1c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55ba8b0ff1c0] kb/s:664.17\n"
     ]
    }
   ],
   "source": [
    "# Render full sequence to MP4 using the in-repo Renderer class.\n",
    "# Vertices are produced by the fused smplx/SMPLX.py forward (no Kabsch, no manual fusion).\n",
    "\n",
    "class SMPLXRenderer:\n",
    "    \"\"\"\n",
    "    Minimal rasterization wrapper around the project's Renderer utilities.\n",
    "\n",
    "    - Projects vertices with orthographic projection (`batch_orth_proj`).\n",
    "    - Adds five front-facing directional lights for simple shading.\n",
    "    - Computes per-vertex normals and per-face attributes for shading.\n",
    "    - Returns shaded RGB images in CHW format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_size : int\n",
    "        Output resolution (square).\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size=800):\n",
    "        # Keep references to static methods on Renderer (already imported in Cell 1)\n",
    "        self.rasterize_fn = Renderer.rasterize\n",
    "        self.add_directionlight_fn = Renderer.add_directionlight\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def render_smplx(self, vertices, cam_params, faces, device):\n",
    "        \"\"\"\n",
    "        Render a batch of SMPL-X meshes using orthographic projection + simple shading.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vertices : torch.Tensor\n",
    "            Tensor of shape [B, V, 3] in world space.\n",
    "        cam_params : torch.Tensor\n",
    "            Tensor of shape [B, 3] for orthographic scale/translation (s, tx, ty).\n",
    "        faces : torch.LongTensor\n",
    "            Tensor of shape [1, F, 3] or [B, F, 3] with triangle indices.\n",
    "        device : str or torch.device\n",
    "            Target device for lighting tensors.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shaded RGB images as a tensor of shape [B, 3, H, W].\n",
    "        \"\"\"\n",
    "        batch_size = vertices.shape[0]\n",
    "\n",
    "        # Orthographic projection with small Z push to ensure front visibility\n",
    "        transformed_vertices = batch_orth_proj(vertices, cam_params)\n",
    "        transformed_vertices = transformed_vertices.clone()\n",
    "        transformed_vertices[:, :, 2] = transformed_vertices[:, :, 2] + 10\n",
    "\n",
    "        # Five simple front lights (xyz + intensity)\n",
    "        light_positions = torch.tensor([\n",
    "            [-1, -1, -1], [1, -1, -1], [-1, +1, -1], [1, +1, -1], [0, 0, -1]\n",
    "        ])[None, :, :].expand(batch_size, -1, -1).float()\n",
    "        light_intensities = torch.ones_like(light_positions).float() * 1.7\n",
    "        lights = torch.cat((light_positions, light_intensities), 2).to(device)\n",
    "\n",
    "        # Per-vertex and per-face normals\n",
    "        normals = vertex_normals(vertices, faces)\n",
    "        face_normals = face_vertices(normals, faces)\n",
    "\n",
    "        # Simple albedo color (greenish) per vertex -> per face\n",
    "        colors = torch.tensor([12, 156, 91])[None, None, :].repeat(1, vertices.shape[1], 1).float() / 255.0\n",
    "        colors = colors.to(device)\n",
    "        face_colors = face_vertices(colors, faces[0:1] if faces.shape[0] == 1 else faces)\n",
    "        face_colors = face_colors.expand(batch_size, -1, -1, -1)\n",
    "\n",
    "        # Rasterize with attributes [rgb(3) | normal(3)]\n",
    "        attributes = torch.cat([face_colors, face_normals], -1)\n",
    "        rendering = self.rasterize_fn(self, transformed_vertices, faces, attributes)\n",
    "        albedo_images = rendering[:, :3, :, :]\n",
    "        normal_images = rendering[:, 3:6, :, :]\n",
    "\n",
    "        # Lighting/shading in image space\n",
    "        shading = self.add_directionlight_fn(self, normal_images.permute(0, 2, 3, 1).reshape([batch_size, -1, 3]), lights)\n",
    "        shading_images = shading.reshape([batch_size, albedo_images.shape[2], albedo_images.shape[3], 3]).permute(0, 3, 1, 2).contiguous()\n",
    "        shaded_images = albedo_images * shading_images\n",
    "        return shaded_images\n",
    "\n",
    "# Encoder and render loop\n",
    "renderer = SMPLXRenderer(image_size=800)\n",
    "demo_path = '/mnt/fasttalk_upperbody/demo'\n",
    "os.makedirs(demo_path, exist_ok=True)\n",
    "out_video_renderer = os.path.join(demo_path, 'smplx_flame_fused.mp4')\n",
    "fps = 25\n",
    "res = 800\n",
    "use_ffmpeg = shutil.which('ffmpeg') is not None\n",
    "ffmpeg_proc = None\n",
    "\n",
    "if use_ffmpeg:\n",
    "    print('Using ffmpeg (libx264) for H.264 encoding')\n",
    "    ffmpeg_cmd = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-f', 'rawvideo', '-vcodec', 'rawvideo',\n",
    "        '-pix_fmt', 'rgb24', '-s', f'{res}x{res}',\n",
    "        '-r', str(fps), '-i', '-',\n",
    "        '-an', '-vcodec', 'libx264', '-pix_fmt', 'yuv420p',\n",
    "        '-preset', 'veryfast', '-crf', '18', out_video_renderer\n",
    "    ]\n",
    "    ffmpeg_proc = subprocess.Popen(ffmpeg_cmd, stdin=subprocess.PIPE)\n",
    "else:\n",
    "    print('ffmpeg not found; falling back to OpenCV (mp4v)')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(out_video_renderer, fourcc, fps, (res, res), True)\n",
    "    if not writer.isOpened():\n",
    "        raise RuntimeError('OpenCV VideoWriter init failed')\n",
    "\n",
    "print(f'Rendering {len(frame_keys)} frames using SMPLX.py fusion...')\n",
    "\n",
    "# Recompute centering/scale using the fused model first frame\n",
    "with torch.no_grad():\n",
    "    coeffs0 = parse_frame(tracking[frame_keys[0]])\n",
    "    param0 = build_param_dict(coeffs0, prefer_flame=True, fd=tracking[frame_keys[0]])\n",
    "    out0 = smplx_fused(param0)\n",
    "    verts0 = out0['vertices']  # [1,V,3]\n",
    "    center_t = verts0.mean(dim=1, keepdim=True)\n",
    "    verts0_centered = verts0 - center_t\n",
    "    scale = float(2.1 / (verts0_centered.abs().max().item() + 1e-6))\n",
    "    cam_params = torch.tensor([[scale, 0.0, 0.0]], dtype=torch.float32, device=device)\n",
    "\n",
    "# Main render loop\n",
    "with torch.no_grad():\n",
    "    for idx, fk in enumerate(frame_keys):  # slice with [:10] for a quick preview\n",
    "        coeffs = parse_frame(tracking[fk])\n",
    "        param = build_param_dict(coeffs, prefer_flame=True, fd=tracking[fk])\n",
    "        out_fused = smplx_fused(param)\n",
    "        verts = out_fused['vertices']\n",
    "        img_t = renderer.render_smplx(verts - center_t, cam_params, faces_t, device)\n",
    "        img_rgb = (img_t[0].detach().cpu().permute(1, 2, 0).numpy().clip(0, 1) * 255).astype(np.uint8)\n",
    "        if use_ffmpeg:\n",
    "            ffmpeg_proc.stdin.write(img_rgb.tobytes())\n",
    "        else:\n",
    "            writer.write(img_rgb[:, :, ::-1])\n",
    "        if (idx + 1) % 5 == 0 or (idx + 1) == len(frame_keys):\n",
    "            print(f'  Rendered {idx + 1}/{len(frame_keys)} frames')\n",
    "\n",
    "# Finalize encoder\n",
    "if use_ffmpeg:\n",
    "    ffmpeg_proc.stdin.close(); ffmpeg_proc.wait()\n",
    "else:\n",
    "    writer.release()\n",
    "print(f'âœ“ Saved video to {out_video_renderer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb84d58",
   "metadata": {},
   "source": [
    "## Render to MP4 (H.264)\n",
    "Render all frames with front lights, orthographic projection, and encode via `ffmpeg` using `libx264` + `yuv420p`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasttalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
